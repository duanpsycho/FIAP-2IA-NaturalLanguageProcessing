{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "tZFcDaAUp-f2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "ont8JX9spNZz"
      },
      "cell_type": "markdown",
      "source": [
        "## NLTK"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MtRjU5tRYZQ3",
        "outputId": "9da03c5d-d3dd-4781-caa4-0ba05388a53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('floresta')\n",
        "\n",
        "from nltk import tokenize\n",
        "\n",
        "text = \"Não sei se entendi como ler o conteúdo da view, então. Estou entendendo que a view contém um histórico das movimentações dos associados, certo?\"\n",
        "\n",
        "tokenize.word_tokenize(text, language=\"portuguese\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/floresta.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Não',\n",
              " 'sei',\n",
              " 'se',\n",
              " 'entendi',\n",
              " 'como',\n",
              " 'ler',\n",
              " 'o',\n",
              " 'conteúdo',\n",
              " 'da',\n",
              " 'view',\n",
              " ',',\n",
              " 'então',\n",
              " '.',\n",
              " 'Estou',\n",
              " 'entendendo',\n",
              " 'que',\n",
              " 'a',\n",
              " 'view',\n",
              " 'contém',\n",
              " 'um',\n",
              " 'histórico',\n",
              " 'das',\n",
              " 'movimentações',\n",
              " 'dos',\n",
              " 'associados',\n",
              " ',',\n",
              " 'certo',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kySnyrT1c1sy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import floresta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dqcDbl4mdodH",
        "outputId": "319f5738-4e58-46a1-feb8-26bf40bbd69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "floresta.tagged_words()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Um', '>N+art'), ('revivalismo', 'H+n'), ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RbMcbwmoMoPU"
      },
      "cell_type": "markdown",
      "source": [
        "As tags consistem em algumas informações sintáticas, seguidas por um sinal de mais, seguido por uma tag convencional de POS Tag. Vamos retirar o material antes do sinal de mais:"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W5fSRGEugsgy"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.linguateca.pt/floresta/doc/VISLsymbolset-manual.html"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5D8P4BWEdq45",
        "outputId": "b6bfbdbe-a242-4cab-8f2c-bda60da917a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "def simplify_tag(t):\n",
        "  if \"+\" in t:\n",
        "    return t.split(\"+\")[1]\n",
        "  return t \n",
        "\n",
        "twords = nltk.corpus.floresta.tagged_words()\n",
        "twords = [(w.lower(),simplify_tag(t)) for (w,t) in twords]\n",
        "twords[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('um', 'art'),\n",
              " ('revivalismo', 'n'),\n",
              " ('refrescante', 'adj'),\n",
              " ('o', 'art'),\n",
              " ('7_e_meio', 'prop'),\n",
              " ('é', 'v-fin'),\n",
              " ('um', 'art'),\n",
              " ('ex-libris', 'n'),\n",
              " ('de', 'prp'),\n",
              " ('a', 'art')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8U1EuM1jg_-I",
        "outputId": "c97cdb07-7541-4219-c9df-d682ed584a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(' '.join(word + '/' + tag for (word, tag) in twords[:10]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "um/art revivalismo/n refrescante/adj o/art 7_e_meio/prop é/v-fin um/art ex-libris/n de/prp a/art\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "er6gXU5IhTkM",
        "outputId": "05e7d1f9-4488-4240-9679-3d2dccac92c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import floresta\n",
        "\n",
        "def simplify_tag(t):\n",
        "  if \"+\" in t:\n",
        "    return t.split(\"+\")[1]\n",
        "  return t \n",
        "\n",
        "\n",
        "tsents = floresta.tagged_sents()\n",
        "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in tsents if sent]\n",
        "train = tsents[1000:]\n",
        "test = tsents[:1000]\n",
        "\n",
        "tagger0 = nltk.DefaultTagger('n')\n",
        "print(tagger0.evaluate(test))\n",
        "\n",
        "tagger1 = nltk.UnigramTagger(train, backoff=tagger0)\n",
        "print(tagger1.evaluate(test))\n",
        "\n",
        "tagger2 = nltk.BigramTagger(train, backoff=tagger1)\n",
        "print(tagger2.evaluate(test))\n",
        "\n",
        "tagger3 = nltk.TrigramTagger(train, backoff=tagger2)\n",
        "print(tagger3.evaluate(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.17800040072129833\n",
            "0.8740532959326788\n",
            "0.8900420757363254\n",
            "0.8887998397114807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fI-YYFYUjwIk",
        "outputId": "ef35db2a-a013-4503-f8b4-2088952516fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "twords = tokenize.word_tokenize(text, language=\"portuguese\")\n",
        "\n",
        "tagger2.tag(twords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'v-fin'),\n",
              " ('se', 'pron-pers'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'adv'),\n",
              " ('ler', 'v-inf'),\n",
              " ('o', 'art'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', ','),\n",
              " ('então', 'adv'),\n",
              " ('.', '.'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'v-ger'),\n",
              " ('que', 'conj-s'),\n",
              " ('a', 'art'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'art'),\n",
              " ('histórico', 'adj'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'prop'),\n",
              " ('associados', 'n'),\n",
              " (',', ','),\n",
              " ('certo', 'adj'),\n",
              " ('?', '?')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9iIx3MhZkl-o",
        "outputId": "7656ccca-7b03-4bff-c97b-21bbe97fc467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "tagger1.tag(twords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'v-fin'),\n",
              " ('se', 'pron-pers'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'adv'),\n",
              " ('ler', 'v-inf'),\n",
              " ('o', 'art'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', ','),\n",
              " ('então', 'adv'),\n",
              " ('.', '.'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'v-ger'),\n",
              " ('que', 'pron-indp'),\n",
              " ('a', 'art'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'art'),\n",
              " ('histórico', 'adj'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'prop'),\n",
              " ('associados', 'n'),\n",
              " (',', ','),\n",
              " ('certo', 'adj'),\n",
              " ('?', '?')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "inKncgHXouUe",
        "outputId": "dc4c525d-dd34-4e9b-d849-d35bb5c3dde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "print(nltk.corpus.floresta.readme()[:1500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Portuguese Treebank\n",
            "\n",
            "Projecto Floresta Sinta(c)tica -- http://www.linguateca.pt/Floresta/\n",
            "Version 7.4  Distributed with permission.\n",
            "\n",
            "Penn Treebank format, available from http://linguateca.di.uminho.pt/FS/fs.html\n",
            "\n",
            "Key to tags (http://visl.sdu.dk/visl/pt/portsymbol.html)\n",
            "\n",
            "<ACC          direct object\n",
            "<ACC-PASS     passive use of pronoun 'se'\n",
            "<ADVS, <ADVO  adverbial argument\n",
            "<ADVL         adjunct adverbial\n",
            "<DAT          dative (indirect) object\n",
            "<FOC          focus marker (or right focus bracket)\n",
            "<OC           object complement\n",
            "<PASS         agent of passive\n",
            "<PIV          prepositional object\n",
            "<PRED         free (subject) predicative, right of main verb\n",
            "<SC           subject complement\n",
            "<SUBJ         subject\n",
            ">A            adverbial pre-adject (intensifier before adjective, adverb, pronoun or participle)\n",
            ">N            prenominal modifier\n",
            ">P            modifier of prepositional phrase (intensifier, operator or focus adverb)\n",
            ">S            modifier of clause (intensifier, operator or focus adverb)\n",
            "A<            adverbial post-adject (modifier or argument of adjective, adverb or participle)\n",
            "A<ADV         adverbial argument of attributive participle\n",
            "A<ADVL        adverbial adjunct of attributive participle\n",
            "A<PASS        agent of passive after attributive participle\n",
            "A<PIV         prepositional object of attributive participle\n",
            "A<SC          subject complement of attributive participle\n",
            "ACC>          accusative (direct) object\n",
            "ACC>-PASS     passive use of pronoun 'se'\n",
            "ACC>>         double-fro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WpdWBDZlWrDw"
      },
      "cell_type": "markdown",
      "source": [
        "## TextBlob"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_4kC31vdIlza",
        "outputId": "e384da02-658f-4e76-f98d-add3414cfda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "udjWzyToWuKb",
        "outputId": "4353d0ed-2357-42c7-96a2-a9f58fd67490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "opinion = TextBlob(\"EliteDataScience.com is dope!\", analyzer=NaiveBayesAnalyzer())\n",
        "opinion.sentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(classification='neg', p_pos=0.35000000000000003, p_neg=0.6499999999999997)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xM5jokbDglMJ",
        "outputId": "1f56de0e-fdb5-477a-f3f3-f4d5c26a272c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "print(\"Frase original: \", text)\n",
        "\n",
        "tblob = TextBlob(text)\n",
        "\n",
        "print('Idioma: ',tblob.detect_language())\n",
        "\n",
        "en_tblob = tblob.translate(to='en')\n",
        "\n",
        "print(\"Traduzido: \", en_tblob)\n",
        "\n",
        "print(\"Tags: \", en_tblob.tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "Frase original:  Não sei se entendi como ler o conteúdo da view, então. Estou entendendo que a view contém um histórico das movimentações dos associados, certo?\n",
            "Idioma:  pt\n",
            "Traduzido:  I do not know if I understood how to read the contents of the view, then. I understand that the view contains a history of member movements, right?\n",
            "Tags:  [('I', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('know', 'VB'), ('if', 'IN'), ('I', 'PRP'), ('understood', 'VBD'), ('how', 'WRB'), ('to', 'TO'), ('read', 'VB'), ('the', 'DT'), ('contents', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('view', 'NN'), ('then', 'RB'), ('I', 'PRP'), ('understand', 'VBP'), ('that', 'IN'), ('the', 'DT'), ('view', 'NN'), ('contains', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('of', 'IN'), ('member', 'NN'), ('movements', 'NNS'), ('right', 'RB')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tZFcDaAUp-f2"
      },
      "cell_type": "markdown",
      "source": [
        "## SpaCy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ii4EiP-ciUGo",
        "outputId": "895a653e-d731-4ce6-8e24-4e4a5c2eace5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Collecting numpy>=1.15.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Collecting pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz (38.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 38.7MB 47.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "  Running setup.py install for pt-core-news-sm ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed pt-core-news-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "\n",
            "    You can now load the model via spacy.load('pt')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cxv4W49BqDC_",
        "outputId": "d1784b7c-037e-4608-a771-534a194a6fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "doc = nlp(u'Você encontrou o livro que eu te falei, Carla?')\n",
        "\n",
        "print([token.orth_ for token in doc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', ',', 'Carla', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kihe7mhKrZFQ",
        "outputId": "144f46c4-f411-430e-8388-f521d61f5f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "[(token.orth_, token.pos_, token.dep_, spacy.explain(token.dep_)) for token in doc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Machado', 'VERB', 'nsubj', 'nominal subject'),\n",
              " ('de', 'ADP', 'case', None),\n",
              " ('Assis', 'PROPN', 'nmod', 'modifier of nominal'),\n",
              " ('um', 'DET', 'det', 'determiner'),\n",
              " ('dos', 'VERB', 'amod', 'adjectival modifier'),\n",
              " ('melhores', 'ADJ', 'amod', 'adjectival modifier'),\n",
              " ('escritores', 'NOUN', 'appos', 'appositional modifier'),\n",
              " ('do', 'ADP', 'case', None),\n",
              " ('Brasil', 'PROPN', 'nmod', 'modifier of nominal'),\n",
              " (',', 'PUNCT', 'punct', 'punctuation'),\n",
              " ('foi', 'VERB', 'cop', 'copula'),\n",
              " ('o', 'DET', 'det', 'determiner'),\n",
              " ('primeiro', 'ADJ', 'amod', 'adjectival modifier'),\n",
              " ('presidente', 'NOUN', 'ROOT', None),\n",
              " ('da', 'ADP', 'case', None),\n",
              " ('Academia', 'PROPN', 'nmod', 'modifier of nominal'),\n",
              " ('Brasileira', 'PROPN', 'flat:name', None),\n",
              " ('de', 'ADP', 'case', None),\n",
              " ('Letras', 'PROPN', 'nmod', 'modifier of nominal')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "p4IKxyc0ghgX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma lista completa de dependências sintáticas pode ser vista em: https://spacy.io/api/annotation#dependency-parsing \n",
        "\n",
        "Um bom material complementar para dependências sintáticas pode ser vista no [\"Stanford typed dependencies manual\"](https://nlp.stanford.edu/software/dependencies_manual.pdf)\n"
      ]
    },
    {
      "metadata": {
        "id": "lX_bRMWpKE3R",
        "colab_type": "code",
        "outputId": "4965e989-70cc-49f0-ffce-62d705832774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "[token.lemma_ for token in doc if token.pos_ == 'VERB']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encontrar', 'falar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "yD_Mmy2YKE3U",
        "colab_type": "code",
        "outputId": "f3b533ee-d844-46c9-81a6-4076bb714ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "doc = nlp(u'encontrei, encontraram, encontrarão, encontrariam')\n",
        "[token.lemma_ for token in doc if token.pos_ == 'VERB']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encontrar', 'encontrar', 'encontrar', 'encontrar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "_NPR6lntKE3X",
        "colab_type": "code",
        "outputId": "fae1be7a-3cff-4212-d27f-4d879b214e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "doc = nlp(u'Machado de Assis um dos melhores escritores do Brasil, \\\n",
        "foi o primeiro presidente da Academia Brasileira de Letras')\n",
        "doc.ents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Machado de Assis, Brasil, Academia Brasileira de Letras)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "F9APZK79KE3b",
        "colab_type": "code",
        "outputId": "d999c690-1e11-46f4-a644-a1a3a3e11ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "[(entity, entity.label_) for entity in doc.ents]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Machado de Assis, 'PER'),\n",
              " (Brasil, 'LOC'),\n",
              " (Academia Brasileira de Letras, 'ORG')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "Ru_7c5mpia4E",
        "colab_type": "code",
        "outputId": "eaec1bdd-b425-4812-db5a-f4a8b2a12bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "doc8 = nlp(u'Apple investirá $6 milhões')\n",
        "\n",
        "for token in doc8:\n",
        "    print(token.text, end=' | ')\n",
        "\n",
        "print('\\n----')\n",
        "\n",
        "for ent in doc8.ents:\n",
        "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple | investirá | $ | 6 | milhões | \n",
            "----\n",
            "Apple - ORG - Companies, agencies, institutions, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RzVAI0Z6KE3g",
        "colab_type": "code",
        "outputId": "67979648-a7af-4d15-a2fe-6d106e7ddd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "doc4 = nlp('Esta é a primeira sentença. Esta é a segunda sentença. Esta é a terceira. Você já entendeu né?')\n",
        "\n",
        "for sent in doc4.sents:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esta é a primeira sentença.\n",
            "Esta é a segunda sentença.\n",
            "Esta é a terceira.\n",
            "Você já entendeu né?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5E6jPE6yh38K",
        "colab_type": "code",
        "outputId": "6f485bb2-4b15-4126-9a40-d9c339cb7d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(doc4[6])\n",
        "print(doc4[6].is_sent_start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esta\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GPqiHvM7h8Np",
        "colab_type": "code",
        "outputId": "b0c775cc-bf5c-44d4-af61-87c2e94ecb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(nlp.Defaults.stop_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'partir', 'sexto', 'nosso', 'além', 'estive', 'ora', 'dão', 'somos', 'põem', 'foste', 'dezoito', 'deve', 'direita', 'ela', 'parece', 'umas', 'esta', 'pois', 'era', 'vez', 'estou', 'veja', 'apoia', 'conhecida', 'aos', 'nesta', 'nenhuma', 'meus', 'quarta', 'ser', 'nossas', 'nesse', 'naquele', 'só', 'tive', 'bastante', 'estar', 'vinda', 'fazes', 'mil', 'agora', 'dezasseis', 'através', 'algumas', 'as', 'à', 'contra', 'mais', 'tu', 'todo', 'pouca', 'nada', 'aquela', 'tarde', 'seus', 'vossos', 'vais', 'próximo', 'após', 'ver', 'ainda', 'muito', 'sobre', 'nem', 'às', 'lugar', 'tua', 'quarto', 'quinto', 'naquela', 'dar', 'grupo', 'estes', 'porquê', 'sétimo', 'quem', 'são', 'eventual', 'tiveram', 'tivestes', 'neste', 'um', 'corrente', 'fazia', 'seria', 'número', 'tanta', 'boa', 'questão', 'mal', 'aquele', 'sétima', 'estão', 'para', 'estará', 'lhe', 'segundo', 'diante', 'com', 'certeza', 'quanto', 'desde', 'na', 'podem', 'apontar', 'elas', 'muitos', 'tivemos', 'perto', 'cinco', 'dois', 'entre', 'tentaram', 'oitava', 'tenho', 'nuns', 'for', 'tipo', 'podia', 'quero', 'sim', 'foram', 'estás', 'aqueles', 'parte', 'cada', 'de', 'ali', 'novo', 'ter', 'temos', 'acerca', 'comprida', 'ontem', 'vão', 'possível', 'és', 'quieto', 'tem', 'esses', 'por', 'dezanove', 'esse', 'pelos', 'sua', 'teu', 'enquanto', 'contudo', 'minha', 'vai', 'fazeis', 'puderam', 'iniciar', 'vindo', 'ele', 'poder', 'pontos', 'des', 'sem', 'catorze', 'está', 'embora', 'já', 'primeiro', 'vos', 'grande', 'maior', 'último', 'ligado', 'daquela', 'sou', 'algo', 'faço', 'teve', 'lado', 'isso', 'sabe', 'tuas', 'meio', 'assim', 'posso', 'aqui', 'próxima', 'fez', 'esteve', 'dez', 'primeira', 'em', 'comprido', 'tendes', 'favor', 'custa', 'vêm', 'dizer', 'dá', 'essas', 'geral', 'pela', 'dessa', 'grandes', 'zero', 'maioria', 'qualquer', 'quinze', 'fui', 'dentro', 'tempo', 'três', 'inicio', 'tiveste', 'daquele', 'usa', 'poderá', 'tente', 'obrigado', 'foi', 'tal', 'alguns', 'obrigada', 'desta', 'teus', 'adeus', 'estado', 'depois', 'fomos', 'lá', 'uns', 'devem', 'estivemos', 'posição', 'tentei', 'tudo', 'bom', 'fazer', 'terceira', 'cima', 'ou', 'duas', 'nossos', 'terceiro', 'vós', 'seu', 'vezes', 'os', 'demais', 'eles', 'se', 'povo', 'aquilo', 'próprio', 'sexta', 'fazemos', 'apenas', 'eu', 'longe', 'este', 'mesmo', 'me', 'números', 'te', 'sois', 'coisa', 'minhas', 'onze', 'estava', 'nos', 'não', 'doze', 'fostes', 'fim', 'nível', 'quinta', 'treze', 'outras', 'atrás', 'tanto', 'oitavo', 'mês', 'estiveram', 'exemplo', 'quais', 'põe', 'uma', 'nunca', 'conhecido', 'fazem', 'sistema', 'quê', 'inclusive', 'querem', 'pelas', 'cá', 'estivestes', 'estiveste', 'fora', 'pôde', 'você', 'têm', 'diz', 'sempre', 'porquanto', 'logo', 'estas', 'ir', 'aí', 'num', 'momento', 'cuja', 'falta', 'quer', 'sete', 'pegar', 'forma', 'ao', 'todas', 'porque', 'nós', 'saber', 'vem', 'isto', 'aquelas', 'certamente', 'tens', 'conselho', 'meu', 'sei', 'vens', 'pouco', 'vocês', 'todos', 'disso', 'menos', 'seis', 'das', 'nove', 'também', 'nas', 'pode', 'antes', 'vinte', 'nessa', 'dos', 'tão', 'tentar', 'debaixo', 'vosso', 'quatro', 'possivelmente', 'cento', 'ponto', 'desse', 'portanto', 'quieta', 'relação', 'numa', 'nova', 'ambas', 'local', 'ambos', 'cujo', 'novas', 'somente', 'no', 'menor', 'final', 'toda', 'dezassete', 'apoio', 'breve', 'caminho', 'talvez', 'mas', 'outra', 'tais', 'vossas', 'área', 'meses', 'pelo', 'então', 'do', 'deste', 'é', 'bem', 'oito', 'maiorias', 'onde', 'novos', 'usar', 'irá', 'suas', 'da', 'faz', 'valor', 'segunda', 'sob', 'essa', 'ademais', 'como', 'baixo', 'nossa', 'máximo', 'fará', 'dizem', 'outros', 'porém', 'qual', 'até', 'vossa', 'vários', 'deverá', 'quando', 'cedo', 'que'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AWKYCRDojNR2",
        "colab_type": "code",
        "outputId": "9750cd8d-a42c-45f3-aeb1-eb7eeb9ff40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "u6UGby2DjU64",
        "colab_type": "code",
        "outputId": "121179a3-07d2-48ae-e744-58f04924fea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "len(stopwords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "XJtqP-KFjgem",
        "colab_type": "code",
        "outputId": "39574999-b27e-417e-e906-66ee94b9fcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "list(set(nlp.Defaults.stop_words) - set(stopwords))[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['grandes',\n",
              " 'logo',\n",
              " 'sexto',\n",
              " 'partir',\n",
              " 'zero',\n",
              " 'tentaram',\n",
              " 'maioria',\n",
              " 'qualquer',\n",
              " 'oitava',\n",
              " 'quinze']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "IukkB7hUku9M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Correspondência Baseada em Regras \n",
        "\n",
        "O spaCy oferece uma ferramenta de correspondência de regras chamada Matcher, que permite criar uma biblioteca de padrões de token e, em seguida, associar esses padrões a um objeto Doc para retornar uma lista de correspondências encontradas. Você pode combinar em qualquer parte do token, incluindo texto e anotações, e você pode adicionar vários padrões ao mesmo combinador."
      ]
    },
    {
      "metadata": {
        "id": "uutHbv8UkGaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "trlgtXz5lJ6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui matcher é um objeto que é emparelhado com o objeto Vocab atual. Podemos adicionar e remover matchers nomeados específicos para o matcher, conforme necessário."
      ]
    },
    {
      "metadata": {
        "id": "ZiJM5rJ1loqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos encontrar o termo \"guarda-chuva\" como uma palavra ou duas, com ou sem um hífen. Nesta seção, vamos desenvolver um matcher que encontre todos os três:"
      ]
    },
    {
      "metadata": {
        "id": "iITO-2i-lBCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pattern1 = [{'LOWER': 'guardachuva'}]\n",
        "pattern2 = [{'LOWER': 'guarda'}, {'LOWER': 'chuva'}]\n",
        "pattern3 = [{'LOWER': 'guarda'}, {'IS_PUNCT': True}, {'LOWER': 'chuva'}]\n",
        "\n",
        "matcher.add('GuardaChuva', None, pattern1, pattern2, pattern3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5TSsvpsmDvV",
        "colab_type": "code",
        "outputId": "3dbe8227-97bb-4f04-d65b-f99d8d90bef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "doc = nlp('Hoje eu esqueci meu guardachuva. Vou ter que comprar um novo guarda-chuva. Quanto custa um guarda chuva?')\n",
        "\n",
        "found_matches = matcher(doc)\n",
        "print(found_matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(12789480426693079439, 4, 5), (12789480426693079439, 12, 15), (12789480426693079439, 19, 21)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TD4o3trJmflv",
        "colab_type": "code",
        "outputId": "7bdf3082-5adc-4935-d5c7-9a23d51f558c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "for match_id, start, end in found_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "    span = doc[start:end]\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12789480426693079439 GuardaChuva 4 5 guardachuva\n",
            "12789480426693079439 GuardaChuva 12 15 guarda-chuva\n",
            "12789480426693079439 GuardaChuva 19 21 guarda chuva\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t2qY-3uTnFWA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para saber mais sobre esta função da lib SpaCy: https://spacy.io/usage/linguistic-features#section-rule-based-matching"
      ]
    },
    {
      "metadata": {
        "id": "Yns7z1dooSiw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercício"
      ]
    }
  ]
}